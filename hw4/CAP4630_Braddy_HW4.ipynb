{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAP4630-Braddy-HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbraddy/CAP4630-AI/blob/master/hw4/CAP4630_Braddy_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6vnLZ97J_pR",
        "colab_type": "text"
      },
      "source": [
        "# HW4 Summary of Things I Learned In This Class - Michael Braddy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV1G-mUC6d7b",
        "colab_type": "text"
      },
      "source": [
        "**0. General concepts (for instance, what is artificial intelligence, machine learning, deep learning)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcX3ilWS6wXE",
        "colab_type": "text"
      },
      "source": [
        "I'd define Artifical intelligence as a very broad term. I believe any solution to any problem that is formulated in a way that allows it to be solved by a computer is considered Artificial Intelligence and AI is then subdivided into categories of those problems. For example, A* is a solution to a Pathfinding problem and Pathfinding is a branch of Artificial Intelligence. Or perhaps more applicable to this class, Convolutional Neural Networks are a solution to a Machine Learning problem which is also a branch of Artificial Intelligence.\n",
        "\n",
        "Machine Learning itself is a method of data analysis based on the idea that a computer is capable of identifying patterns and making decisions based on those patterns with very little human intervention. One of the subsets of machine learning that we covered in this class is Deep Learning.\n",
        "\n",
        "Deep Learning can then be defined as a method of teaching a computer on how to think and process unstructured inputs by breaking down an input layer by layer. It establishes a network of layers that each process the output of the previous layer and examine finer and finer details until the desired output is reached. Learning this way does require extensive training and self regulation of the loss and accuracy of the neural network model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPHRb-m26h7r",
        "colab_type": "text"
      },
      "source": [
        "**1. Building a model (for instance, here you can talk about the structure of a convent, what it components are etc.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6bQaMGv92qU",
        "colab_type": "text"
      },
      "source": [
        "The neural network itself is called a model. These models can be structured in several ways, (such as functional or sequential) but the way we did it in this class was through sequential models.\n",
        "\n",
        "A sequential model is a neural network model that allows you to build sequential layers to handle one source of input. Similarly to a aqueous filter, you input your initial type of data and each layer that it passes through removes something. The difference is that the neural net then processes what is relevant to identifying what the original input is at each layer until there is nothing left. This allows the model to then match the components of the input to a known dataset in order for it to determine/guess what the input was originally by labeling the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X9GqzM96j48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "84f483fa-2915-4977-e8b1-2fffce5e65d3"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Loading example dataset [Code taken from HW1]\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "\n",
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)\n",
        "\n",
        "# Constructing the model - Define the Structure then add the layers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5GgAtg96kQk",
        "colab_type": "text"
      },
      "source": [
        "**2. Comping a model (for instance, you can talk here about optimizers, learning rate etc.)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj5hnxOtBVFS",
        "colab_type": "text"
      },
      "source": [
        "After constructing the model we then compile the model. When compiling the model we need to define the optimizer, the loss function, and define the metrics that we care about examining. In this case, that metric is accuracy.\n",
        "\n",
        "The loss function itself is a function that maps how well our specific algorithm maps to the trained data. If the loss gets too high then we know that the algorithm is deviating greatly from our desired results and that the predictions of the neural net are going to be way off.\n",
        "\n",
        "In order to keep the loss function useful, we utilize a tuning parameter called the learning rate. This allows us to limit the step size each iteration so that we don't over-shoot the minima of the loss function.\n",
        "\n",
        "The Optimizer itself ties the model to the loss function by looking at the loss and then adjusting the weights (or parameters) of our models in order to minimize the loss. This guides the model in the right direction towards minimizing the loss and giving our model a greater chance of making accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTUx1MQR6mwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yta20Df6nME",
        "colab_type": "text"
      },
      "source": [
        "**3. Training a model (for instance, you can talk about overfitting/underfitting)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9s8MCwXEPvD",
        "colab_type": "text"
      },
      "source": [
        "When your model has been compiled, the next step is to train it. In order to train the model we first take it and run it through a *large* dataset of example inputs and tell the model what each input is. We perform this step for multiple iterations (epochs) until we believe we have a good fit for our data. This is important so that we are neither underfitting or overfitting our dataset.\n",
        "\n",
        "Underfitting our dataset would be bad because this means that we did not train the network long/well enough and that our model is not as accurate as it could be. This would provide us with a high degree of inaccuracy and make our network unreliable.\n",
        "\n",
        "Overfitting our dataset would also be bad but for different reasons. Overfitting datasets means that our model is so good that it's even capturing the noise (generalized differences between the inputs that shouldn't matter). This can be caused by running for too many epochs or by inputting already properly validated data too many times.\n",
        "\n",
        "In this example I'm using the MNIST dataset from homework 1.\n",
        "\n",
        "Training gives our model a baseline on what a correct answer should look like so that it can then evaluate un-labeled information entirely on it's own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuygJkO76p0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "3b5c03d5-2739-4055-83df-13643b097da8"
      },
      "source": [
        "# Define epochs, train the model 10 times on the train data sets then run the model on test_images\n",
        "epochs = 10\n",
        "history = network.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.1300 - acc: 0.9617 - val_loss: 0.1035 - val_acc: 0.9688\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0818 - acc: 0.9755 - val_loss: 0.0783 - val_acc: 0.9769\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0583 - acc: 0.9827 - val_loss: 0.0774 - val_acc: 0.9765\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0446 - acc: 0.9861 - val_loss: 0.0719 - val_acc: 0.9777\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0343 - acc: 0.9898 - val_loss: 0.0683 - val_acc: 0.9803\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0266 - acc: 0.9921 - val_loss: 0.0668 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0213 - acc: 0.9936 - val_loss: 0.0665 - val_acc: 0.9799\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0163 - acc: 0.9950 - val_loss: 0.0680 - val_acc: 0.9815\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.0712 - val_acc: 0.9812\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0105 - acc: 0.9971 - val_loss: 0.0711 - val_acc: 0.9818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9SzZr7I6qFd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**4.  Finetuning  a pretrained model (describe how you proceed)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTfYYYF6H3Tm",
        "colab_type": "text"
      },
      "source": [
        "In order to finetune our model we can do several things. To reduce overfitting we could add droupout or normalization. This would allow us to remove/alter (respectively) already validated samples so that our model wouldn't update it's weights on already good answers. To reduce underfitting we could add more layers to the network or up the epoch count. Ultimately what we do would change on a model to model basis.\n",
        "\n",
        "For example, the model included on this page is a good fit to the MNIST dataset thus it doesn't need any finetuning done to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt3Vo3I66rdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ef1f6998-c818-47ea-843b-aec8bc5431c2"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create Predictions\n",
        "predictions = network.predict(test_images)\n",
        "\n",
        "plt.imshow(test_images[1].reshape(28, 28))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6b0a619908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqCslOc7JGlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c84886c-09e5-452a-838b-42d050e8ff47"
      },
      "source": [
        "np.round(predictions[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhLqx97yJKja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a91d945b-79ef-4ce7-f1f4-9532e949d0e7"
      },
      "source": [
        "test_labels[1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}